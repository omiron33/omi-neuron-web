# Ingestion (Connectors + CLI)

Phase 7C adds a connector-based ingestion system so you can bring real-world content into the graph with minimal glue code.

## Concepts
- A **connector** fetches + normalizes external content into `IngestionRecord`s.
- The **ingestion engine** writes nodes/edges into a `GraphStore` (Postgres or local-first).
- A **source** is a configured connector instance (`type` + `name` + `config`).

See:
- `docs/phase-7c/ingestion-model.md`
- `docs/phase-7c/connector-contract.md`

## CLI quickstart

The CLI reads `neuron.config.ts` (generated by `omi-neuron init`) to determine storage mode.

Markdown:
```bash
omi-neuron ingest markdown --source docs --path ./docs
```

GitHub:
```bash
omi-neuron ingest github --source omi --repo owner/name --state open
```

RSS:
```bash
omi-neuron ingest rss --source news --url https://example.com/feed.xml
```

Notion export:
```bash
omi-neuron ingest notion --source notion --path ./notion-export
```

Dry-run (no writes):
```bash
omi-neuron ingest markdown --source docs --path ./docs --dry-run
```

## Programmatic usage

```ts
import { IngestionEngine, MarkdownConnector, MemoryProvenanceStore, InMemoryGraphStore } from '@omiron33/omi-neuron-web';

const store = new InMemoryGraphStore();
const engine = new IngestionEngine(store, new MemoryProvenanceStore());

const connector = new MarkdownConnector({ path: './docs' });
const records = await connector.listRecords();

await engine.ingest(records, {
  source: { type: connector.type, name: 'docs', config: { path: './docs' } },
});
```

